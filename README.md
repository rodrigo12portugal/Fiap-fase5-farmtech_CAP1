
## üéØ Objetivo do Projeto

- **An√°lise Explorat√≥ria (EDA)**: entender a base de dados, tipos de vari√°veis, correla√ß√µes e distribui√ß√µes.  
- **Clusteriza√ß√£o e Outliers**: segmentar condi√ß√µes de plantio via PCA+KMeans e detectar cen√°rios at√≠picos com IsolationForest.  
- **Modelagem Preditiva**: treinar 5 modelos de regress√£o supervisionada (`LinearRegression`, `Ridge`, `RandomForestRegressor`, `GradientBoostingRegressor`, `SVR`) para prever rendimento.  
- **Boas Pr√°ticas de ML**: pipelines reprodut√≠veis, valida√ß√£o cruzada (`RepeatedKFold`), `GridSearchCV` leve para ajuste de hiperpar√¢metros, m√©tricas adequadas.  
- **Conclus√£o e Relat√≥rio**: se√ß√£o final com pontos fortes, limita√ß√µes e sugest√µes de pr√≥ximos passos.


## üîß Requisitos

Para executar o notebook, instale os pacotes necess√°rios (Python 3.10+):

```bash
pip install pandas numpy matplotlib scikit-learn joblib

```
## üìä Principais Resultados
| Modelo           | RMSE\_cv | RMSE\_test | MAE\_test   | R¬≤\_test |
| ---------------- | -------- | ---------- | ----------- | -------- |
| LinearRegression | 8414.80  | 4527.90    | 3315.96     | 0.9947   |
| Ridge            | 8307.77  | 4599.03    | 3328.58     | 0.9945   |
| RandomForest     | 7739.66  | 4630.46    | **2619.19** | 0.9944   |
| GradientBoosting | 7890.13  | 5447.90    | 2720.43     | 0.9923   |
| SVR              | 83351.93 | 71292.83   | 38948.07    | -0.31    |


RandomForestRegressor ‚Üí menor MAE, modelo mais robusto para previs√£o.

LinearRegression ‚Üí excelente ajuste (R¬≤ ‚âà 0.9947), sugere padr√£o linear forte.

SVR ‚Üí desempenho ruim (descartado).

Clusteriza√ß√£o revelou grupos distintos de rendimento; outliers foram identificados para investiga√ß√£o.

## üìù Pontos Fortes

- Pipeline completo: pr√©-processamento, imputa√ß√£o, normaliza√ß√£o, e modelos em um √∫nico objeto.
- Reprodutibilidade: random_state fixo e se√ß√£o com vers√µes de bibliotecas.
- Visualiza√ß√µes: histogramas, matriz de correla√ß√£o, PCA, boxplots por cluster, gr√°fico de import√¢ncia de vari√°veis.
- Entrega pronta: c√≥digo comentado, c√©lulas de Markdown organizadas, artefatos salvos.

## ‚ö†Ô∏è Limita√ß√µes

- Busca de hiperpar√¢metros reduzida (para execu√ß√£o r√°pida); tuning maior pode melhorar ensembles.
- Clusteriza√ß√£o feita em PCA 2D; m√©todos mais avan√ßados (UMAP/t-SNE) podem explorar melhor a estrutura dos dados.

## üë®‚Äçüíª Autores
- Projeto desenvolvido por [Rodrigo Portugal Santos, Carlos Daniel Silveira Do Nascimento, Mauricio Jose Ferlin Tonnera] para a FIAP ‚Äî Fase 5 do curso.
